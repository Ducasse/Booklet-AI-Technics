!! A-Priori Algorithm for Mining Frequent Itemsets

Modern retailers collect massive amounts of sales data - the logs of online and offline transactions that are commonly referred to as the ''basket data''. This data allows us to analyse customer behavior and make better management decisions. Which items should we put on sale? How to group items together on the shelves? Which items should we recommend to a specific customer?

Many of these problems can be solved by scanning the database of transactions and identifying ''frequent itemsets'' - the groups of products that are often purchased together. If we know that customers tend to buy bread, butter, and milk together, then we can place them close to each other.

By finding frequent sets of items, we can also produce association rules between products. For example, if we realise that bread, butter, and milk appear together in more than 5\% of transactions, we can go further and calculate that 90\% of customers who purchase bread and butter, also purchase milk. This gives us an association rule {bread, butter} {{{$\Rightarrow$}}} {milk} that can be used to recommend products to customers or sell them together with a discount.

In this chapter, we discuss ''A-Priori'' - a fast and efficient algorithm for mining frequent itemsets and finding association rules.

!!! Applications
@sec:APriori-Applications

The applications of A-Priori go far beyond market basket analysis.


!!! Formal Definition
@sec:APriori-Definition

In this section, we give a formal definition of the problem and the A-Priori algorithm. We will go slowly through the math and help you understand the algorithm in all its details before we start implementing it.

!!! The Problem of Mining Frequent Itemsets

You are given a set of items called ''item base''. Think of those items as products that are sold at the supermarket:

{{{
\[ B = \{ i_1, \dots, i_n \} \]
}}}

You are also given a set of ''transactions'' {{{$T$}}} where each transaction is a set of items from the item base {{{$B$}}}. Each transaction can represent one receipt - a list of products purchased by a customer in the supermarket:

{{{
\[ T = \{ t_1, \dots, t_m \} \]
\[ \forall t_k \in T \quad t_k \subseteq B \]
}}}

We use the word ''itemset'' to denote any set of items selected from the item base:

{{{
\[ I \subseteq B \]
}}}

In fact, every transaction is an itemset (a set of items that were purchased by a customer) and the item base itself is also an itemset (a set of all products in the supermarket).

We say that itemset {{{$I$}}} ''appears'' in transaction {{{$t$}}} if {{{$t$}}} contains all items from {{{$I$}}}. This means that {{{$I$}}} is a subset of {{{$t$}}}, {{{$I \subseteq t$}}}. We can also say that transaction {{{$t$}}} ''contains'' itemset {{{$I$}}}.

The ''count'' of an item set {{{$I$}}} in a set of trasactions {{{$T$}}} is the number of transactions in which this itemset appears:

{{{
\[ count(I) = | \{ t_k \in T | I \subseteq t_k \} | \]
}}}

The ''support'' of an itemset {{{$I$}}} is the relative frequency of this itemset in a set of transactions {{{$T$}}} - the percentage of transactions that contain all items from itemset {{{$I$}}}:

{{{
\[ support(I) = \frac{count(I)}{|T|} \]
}}}

where {{{$|T|$}}} is the total number of transactions.

Support has a probabilistic interpretation - it is a probability that customer buys all items from itemset {{{$I$}}}:

{{{\[ support(I) = P(I) \]}}}

Given some ''minimum support'' {{{$ minsup \in \mathbb{N} $}}}, an itemset {{{$I$}}} is called ''frequent'' if its support {{{$support(I)$}}} is greater than or equal to the minimum support.

The set of all frequent itemsets in a database of transactions {{{$T$}}} with a support threshold {{{$minsup$}}} is denoted {{{$\mathcal{F}_T(minsup)$}}}. For simplicity, we will write just {{{$\mathcal{F}$}}}:

{{{
\[ \mathcal{F} = \{ I \subseteq B | support(I) \geq minsup \} \]
}}}

{{{
\begin{tcolorbox}
The goal of frequent itemset mining is to find the set of all frequent itemsets $\mathcal{F}$ given a set of transactions $T$ and a minimum support $minsup$.
\end{tcolorbox}
}}}

!!! Example Part 1: Problem Definition

In this section, we give a simple example of finding frequent itemsets and association rules using A-Priori algorithm.

Given a support threshold {{{$minsup = 1/3$}}}, we need to find frequent itemsets in the following database of transactions {{{$T$}}}${footnote:In practice, it is faster to encode all items with integers before applying the APriori algorithm, and then decode the results before presenting them to the user. But encoding is optional and in this example, we process items as strings to make it more clear what is going on. We will discuss item encoding in Section *@sec:APriori-Implementation*.}$:

|! TID |! Transaction
| 1 | {eggs, milk, butter}
| 2 | {milk, cereal}
| 3 | {eggs, bacon}
| 4 | {bread, butter}
| 5 | {bread, bacon, eggs}
| 6 | {bread, avocado, butter, bananas}

This means that we have to identify all possible combinations of products that appear in at least 33.33\% of transactions (at least 2 out of 6).

The item base is the set of all products that appear in transactions:

{{{
\[ B = \{ eggs, milk, butter, cereal, bacon, bread, avocado, bananas \} \]
}}}

!!! Why This is a Complicated Problem?

So far, the problem does not seem complicated: you can find all frequent itemsets in a database of transactions simply by iterating over all possible itemsets and selecting the ones that pass the minimum support threshold:

[[[
itembase combinations select: [ :itemset |
    itemset support >= minsup ].
]]]

However, the number of possible itemsets grows very quickly as you increase the size of an item base {{{$B$}}}{{{\footnote{The collection of all possible subsets of $B$ is called \textit{powerset} and denoted $\mathbb{P}(B)$} }}}:

{{{
\[ |\mathbb{P}(B)| = \sum_{k=0}^{|B|} C_k^{|B|} = 2^{|B|} \]
}}}

Even for the smallest stores that sell very limited amount of products, a set of all possible combinations of those products will be so big that any analysis on this set becomes practically impossible. Here is an example of how fast the number of possible itemsets grows as we increase the number of products:

|! Number of products |! Number of itemsets
| 10 | 1024
| 100 | 1.27e+30
| 1000 | 1.07e+301
| 10,000 | 1.99e+3010

To solve the problem of frequent itemset mining, we must therefore reduce the search space and find a smarter way of iterating throgh the potential candidates.

!!! The A-Priori Property

The idea behind A-Priori algorithm is based on a simple intuitive property of itemsets: ''if itemset I appears in transactions k times, then there can be no itemset J that contains all elements from I and appears more than k times''.

In other words,

{{{
\[ \forall I \subseteq J \subseteq B\ \colon\quad count(I) \geq count(J) \]
}}}

Therefore, if an itemset is not frequent, then no superset of this itemset can be frequent:

{{{
\[ \forall I \subseteq J \subseteq B\ \colon\quad support(I) < minsup\ \ \Rightarrow\ \ support(J) < minsup \]
}}}

!!! A-Priori Algorithm

We start the A-Priori algorithm by what is often called an ''"initialization step"'' - we build a set {{{$L_1$}}} of all frequent itemsets of size 1. We think of every item {{{$i$}}} from the item base {{{$B$}}} as an itemset with 1 element {{{$I = \{ i \}$}}}. Then we select only those itemsets whose support is greater than or equal to the given minimum support threshold {{{$minsup$}}}.

Then we repeat the following two steps with {{{$k = 2, 3, \dots$}}} as long as the set {{{$L_{k-1}$}}} of frequent {{{$(k-1)$}}}-itemsets is not empty:

# ''Candidate generation'': we use the set {{{$L_{k-1}$}}} of frequent {{{$(k-1)$}}}-itemsets to generate {{{$C_k$}}} - a set candidate {{{$k$}}}-itemsets.
# ''Frequent itemset selection'': we construct the set {{{$L_k$}}} of frequent {{{$k$}}}-itemsets by selecting only those candidates from {{{$C_k$}}} that pass the minimum support threshold.

To get a better intuition on the flow of the A-Priori algorithm, take a look on Figure *@figAPriori*. We start with a set of frequent items {{{$L_1$}}}, use it to generate candidates {{{$C_2$}}}, then select frequent pairs {{{$L_2$}}}, and continue this process until we get an empty set {{{$L_k = \varnothing$}}}.

+The flow of A-Priori algorithm>figures/APriori.png|label=figAPriori+

The whole algorithm is formally described with pseudocode as Function *@funAPriori*. The function ==generate_candidates== will be defined in the next section, where we will talk about the process of candidate generation.

{{{
\begin{algorithm}[H]
 \KwData{Database of transactions $T$ and a support threshold $minsup$}
 \KwResult{A set $Freq$ of all frequent itemsets in $T$}
 \Fn{apriori($T$, $minsup$)}{
 	$L_1 \gets$ \{frequent 1-itemsets\}\\
 	\For{($k = 2;\ L_{k-1} \neq \varnothing;\ k++$)}{
 		$C_k \gets$ generate\_candidates($L_{k-1}$)\\
		$L_k \gets \{ I \in C_k | support(I) \geq minsup \}$
 	}
 	$Freq \gets \bigcup_k L_k$ \\
	\KwRet $Freq$
 }
 \caption{A-Priori algorithm}
 \label{funAPriori}
\end{algorithm}
}}}

!!!! Candidate Generation for the A-Priori Algorithm
@sec:APriori-CandidateGeneration

In this section, we will take a closer look at the candidate generation for the A-Priori algorithm. At every iteration, it uses previously generated set {{{$L_{k-1}$}}} of frequent {{{$(k-1)$}}}-itemsets to generate a set {{{$C_k$}}} containing candidate itemsets of size {{{$k$}}}. This is done in two steps:

% I write it in LaTeX because I need to insert equations into the list environment without breaking it into multiple lists
{{{
\begin{enumerate}
\item \textbf{Join step} - we join the set $L_{k-1}$ with itself (this operation is denoted as $L_{k-1} \bowtie L_{k-1}$) according to the rules
\begin{itemize}
\item Every two itemsets $I = \{ i_1, i_2, \dots, i_{k-1} \}$ and $J = \{ j_1, j_2, \dots, j_{k-1} \}$ selected from $L_{k-1}$ can be joined if their first $k-2$ elements are the same and the last element of $I$ is smaller than the last element of $J$ (this ensures that the resulted itemset will be sorted and there will be no duplicate candidates)

\[ (i_1 = j_1) \land (i_2 = j_2) \land \dots \land (i_{k-2} = j_{k-2}) \land (i_{k-1} < j_{k-1}) \]

\item If two itemsets $I$ and $J$ can be joined, we join them into a $k$-itemset $Q$ by taking the first $k-2$ elements that they have in common, and appending to them the last element of $I$ followed by the last element of $J$

\[ Q = \{ i_1, i_2, \dots, i_{k-2}, i_{k-1}, j_{k-1} \} \]
\end{itemize}

\item \textbf{Prune step} - we remove all candidates that have at least one subset of size $k-1$ that is not in $L_{k-1}$.
\end{enumerate}
}}}

You can see the pseudocode of the candidate generation procedure in Function *@funCandidateGeneration*.

{{{
\begin{algorithm}
 \KwData{A set of frequent ($k-1$)-itemsets $L_{k-1}$}
 \KwResult{A set of candidate $k$-itemsets $C_k$}
 \Fn{generate\_candidates($L_{k-1}$)}{
 	$C_k \gets$ \{\}\\
 	\ForAll(\tcp*[f]{join step}){$I \in L_{k-1}$}{
 		\ForAll{$J \in L_{k-1}$}{
			\If{can\_be\_joined($I$, $J$)}{
 				$C_k$.add(join($I$, $J$))
			}
		}
 	}
 	\ForAll(\tcp*[f]{prune step}){$I \in C_k$}{
 		\ForAll{($k-1$)-subsets $I_{k-1} \subset I$} {
			\If{$I_{k-1} \notin L_{k-1}$}{
				$C_k$.remove($I$)\\
				break
			}
		}
 	}
	\KwRet $C_k$
 }
 \Fn{can\_be\_joined(I, J)}{
 	\For{$p \gets 1$ \KwTo $k-2$}{
 		\If{$i_p$ != $j_p$}{
			\KwRet false
		}
	 }
	 \KwRet $i_{k-1} < j_{k-1}$
 }
 \Fn{join(I, J)}{
 	$Q \gets \{\}$ \\
 	\For{$p \gets 1$ \KwTo $k-1$}{
 		Q.add($j_p$)
 	}
 	Q.add($j_{k-1}$) \\
 	\KwRet Q
 }
 \caption{Candidate generation for the A-Priori algorithm}
 \label{funCandidateGeneration}
\end{algorithm}
}}}

!!! Example Part 2: Mining Frequent Itemsets
@sec:APriori-SimpleExample

To initialize the A-Priori algorithm, we need to construct the set {{{$L_1$}}} containing all frequent 1-itemsets. To do that, we first create a set of candidates {{{$C_1$}}} - all items from the encoded item base {{{$B$}}} represented as itemsets of size 1:

{{{
\begin{align*}
C_1 = \{ &\{eggs\}, \{milk\}, \{butter\}, \{cereal\},\\
		 &\{bacon\}, \{bread\}, \{avocado\}, \{bananas\} \}
\end{align*}
}}}

Now we calculate support of each candidate itemset:

|! Itemset |! Support |! Itemset |! Support
| {eggs} | 1/2 | {bacon} | 1/3
| {milk} | 1/3 | {bread} | 1/2
| {butter} | 1/2 | {avocado} | 1/6
| {cereal} | 1/6 | {bananas} | 1/6

We can see that itemsets {{{$\{cereal\}$}}}, {{{$\{avocado\}$}}}, and {{{$\{bananas\}$}}} did not pass the minimum support threshold of 1/3. They don't appear in transactions often enough to be of any interest to us. And based on the A-Priori property, any set of items that includes at least one of those products, can not have higher support than 1/6. Therefore, cereal, avocado, and bananas will be excluded from further analysis.

Other itemsets have passed the support threshold, which means that they are frequent. We collect them into the set of frequent 1-itemsets:

{{{
\[ L_1 = \{ \{eggs\}, \{milk\}, \{butter\}, \{bacon\}, \{bread\} \} \]
}}}

Now we generate the candidates of size 2. To do that, we first join the set of frequent 1-itemsets {{{$L_1$}}} with itself according to the rules of a join step described in Section *@sec:APriori-CandidateGeneration*:

{{{
\begin{align*}
L_1 \bowtie L_1 = \{ &\{eggs, milk\}, \{eggs, butter\}, \{eggs, bacon\}, \{eggs, bread\},\\
					 &\{milk, butter\}, \{milk, bacon\}, \{milk, bread\}, \{butter, bacon\},\\
					 &\{butter, bread\}, \{bacon, bread\} \}
\end{align*}
}}}

Prune step of the algorithm deletes all itemsets of size {{{$k$}}} that contain at least one subset of size {{{$k-1$}}} which is not in {{{$L_{k-1}$}}}. For {{{$k=2$}}}, all itemsets included in {{{$L_1 \bowtie L_1$}}} are composed only of 1-itemsets taken from {{{$L_1$}}}. So the prune step will not delete any items and the set of candidate itemsets is the same as the result of a join step:

{{{
\[ C_2 = L_1 \bowtie L_1 \]
}}}

Once again, we calculate support of all candidate itemsets:

|! Itemset |! Support |! Itemset |! Support
| {eggs, milk} | 1/6 | {milk, bacon} | 0
| {eggs, butter} | 1/6 | {milk, bread} | 0
| {eggs, bacon} | 1/3 | {butter, bacon} | 0
| {eggs, bread} | 1/6 | {butter, bread} | 1/3
| {milk, butter} | 1/6 | {bacon, bread} | 1/6

Only two itemsets have passed the support thresholds, so only they are selected into the set of all frequent 2-itemsets:

{{{
\[ L_2 = \{ \{eggs, bacon\}, \{butter, bread\} \} \]
}}}

On the next iteration, join step produces an empty set, because the only pair of itemsets from {{{$L_2$}}} does not satisfy the join conditions listed in Section *@sec:APriori-CandidateGeneration* and can not be joined:

{{{
\[ L_2 \bowtie L_2 = \varnothing \]
}}}

This means that the set of candidates {{{$C_3$}}} and the set of frequent itemsets {{{$L_3$}}} are also empty and the algorithm stops here:

{{{
\[ C_3 = L_3 = \varnothing \]
}}}

The set of all frequent itemsets is the union of {{{$L_1$}}} and {{{$L_2$}}}:

{{{
\begin{align*}
Freq = L_1 \cup L_2 = \{ &\{eggs\}, \{milk\}, \{butter\}, \{bacon\}, \{bread\},\\
						 &\{eggs, bacon\}, \{butter, bread\} \}
\end{align*}
}}}

Below, you can find the list of frequent itemsets together with their count and support values (remember that count is support multiplied by the total number of transactions {{{$|T| = 6$}}}). These are all possible sets of products that appear in at least 33.33\% of transactions:

|! Frequent itemset |! Count |! Support
| {eggs} | 3 | 1/2
| {milk} | 2 | 1/3
| {butter} | 3 | 1/2
| {bacon} | 2 | 1/3
| {bread} | 3 | 1/2
| {eggs, bacon} | 2 | 1/3
| {butter, bread} | 2 | 1/3

!!! Extracting Association Rules from Frequent Itemsets

Once we have found the set of frequent itemsets {{{$Freq$}}}, we can represent each itemset {{{$Q \in Freq$}}} as a rule in form {{{$I \Rightarrow J$}}} where itemset {{{$I$}}} is a subset of {{{$Q$}}} such that {{{$I \neq \varnothing$}}} and {{{$I \neq Q$}}} and itemset {{{$J$}}} is a complement {{{$Q \setminus I$}}}.

For example, itemset {{{$\{ bread, butter, milk \}$}}} produces 6 association rules:

{{{
\[ \{ bread, butter \} \Rightarrow \{ milk \} \]
\[ \{ bread, milk \} \Rightarrow \{ butter \} \]
\[ \{ butter, milk \} \Rightarrow \{ bread \} \]
\[ \{ bread \} \Rightarrow \{ butter, milk \} \]
\[ \{ butter \} \Rightarrow \{ bread, milk \} \]
\[ \{ milk \} \Rightarrow \{ bread, butter \} \]
}}}

In the context of basket analysis, association rules can be interpreted in the following way:

- {{{$\{ beer, peanuts \} \Rightarrow \{ chips \}$}}} - to every customer who buys beer and peanuts we should also recommend chips.
- {{{$ \{ tea \} \Rightarrow \{ sugar, lemon \} $}}} - to every customer who buys tea we also recommend sugar and lemon.

Every rule {{{$I \Rightarrow J$}}} has count and support in the database of transactions. They are equal to the count and support of the itemset {{{$Q = I \cup J$}}} from which that rule was generated:

{{{
\[ count(I \Rightarrow J) = count(I \cup J) \]
\[ support(I \Rightarrow J) = support(I \cup J) \]
}}}

It is also a common practice to calculate {{{$confidence(I \Rightarrow J)$}}}  and {{{$lift(I \Rightarrow J)$}}} of an association rule and use them to filter rules by specifying minimum confidence {{{$minconf$}}} or minimum lift {{{$minlift$}}} threshold.

!!!! Confidence

''Confidence'' of an association rule {{{$I \Rightarrow J$}}} is a conditional probability of itemset {{{$J$}}} appearing in an arbitrary transaction {{{$t \in T$}}} given that the itemset {{{$I$}}} has appeared in that transaction:

{{{
\[ confidence(I \Rightarrow J) = P(J|I) = \frac{count(I \cup J)}{count(I)} = \frac{support(I \cup J)}{support(I)} \]
}}}

In terms of basket analysis, confidence {{{$confidence(I \Rightarrow J)$}}} tells us what percent of customers who purchased all products from itemset {{{$I$}}} have also purchased all products from itemset {{{$J$}}}.

!!!! Lift

''Lift'' of an association rule {{{$I \Rightarrow J$}}} is a measure of correlation between {{{$J$}}} and {{{$I$}}}:

{{{
\[ lift(I \Rightarrow J) = \frac{P(I \cup J)}{P(I)P(J)} = \frac{support(I \cup J)}{support(I)support(J)} \]
}}}

If occurences of {{{$I$}}} and {{{$J$}}} are independent, then {{{$P(I \cup J) = P(I)P(J)$}}} and {{{$lift(I \Rightarrow J) = 1$}}}. Otherwise, if {{{$lift(I \Rightarrow J) > 1$}}}, this indicates a positive correlation (people who purchased {{{$I$}}} are likely to also purchase {{{$J$}}}) and if {{{$lift(I \Rightarrow J) < 1$}}}, then the correlation is negative (people who purchased {{{$I$}}} will most likely not purchase {{{$J$}}}).

{{{$lift(I \Rightarrow J)$}}} can also be interpreted as a measure of how much the relative frequency of {{{$J$}}} will increase if transactions are restricted to only those that contain {{{$I$}}}:

{{{
\[ lift(I \Rightarrow J) = \frac{confidence(I \Rightarrow J)}{confidence(\varnothing \Rightarrow J)} = \frac{confidence(I \Rightarrow J)}{support(J)} \]
}}}

We invite you to prove that those two definitions of lift are equivalent.

!!! Example Part 3: Mining Association Rules

In this example, we will use frequent itemsets found in Section *@sec:APriori-SimpleExample* to produce association rules for the two values of minimum confidence threshold: {{{$minconf = 2/3$}}} and {{{$minconf = 1$}}}.

Any itemset with at least 2 elements can produce multiple association rules. In our case, we only have two frequent itemsets with more than 1 element: {eggs, bacon} and {butter, bread}.

Knowing that itemset {eggs, bacon} is frequent (customers often buy eggs and bacon together), we can generate two association rules from it:

{{{
\[ \{ eggs \} \Rightarrow \{ bacon \} \]
\[ \{ bacon \} \Rightarrow \{ eggs \} \]
}}}

First rule means that we should recommend bacon to every customer who buys eggs. Second rule goes the other way around - recommend eggs to every customer who buys bacon. Notice that these are different rules and one of them may be more relevant than the other.

To measure the relevance of these rules, we calculate their confidence:

{{{
\[ confidence(\{ eggs \} \Rightarrow \{ bacon \}) = \frac{support(\{ eggs, bacon \})}{support(\{ eggs \})} = \frac23 \]
\[ confidence(\{ bacon \} \Rightarrow \{ eggs \}) = \frac{support(\{ eggs, bacon \})}{support(\{ bacon \})} = 1 \]
}}}

We see that 2 out of 3 customers who bought eggs have also bought bacon. And 100\% of customers who bought bacon have also bought eggs.

We can use the value of confidence to calculate the lift of those rules:

{{{
\[ lift(\{ eggs \} \Rightarrow \{ bacon \}) = \frac{confidence(\{ eggs \} \Rightarrow \{ bacon \})}{support(\{ bacon \})} = 2 \]
\[ lift(\{ bacon \} \Rightarrow \{ eggs \}) = \frac{confidence(\{ bacon \} \Rightarrow \{ eggs \})}{support(\{ eggs \})} = 2 \]
}}}

Now let's produce rules from the second itemset {butter, bread}:

{{{
\[ \{ butter \} \Rightarrow \{ bread \} \]
\[ \{ bread \} \Rightarrow \{ butter \} \]
}}}

Again, we calculate the confidence of both rules:

{{{
\[ confidence(\{ butter \} \Rightarrow \{ bread \}) = \frac{support(\{ butter, bread \})}{support(\{ butter \})} = \frac23 \]
\[ confidence(\{ bread \} \Rightarrow \{ butter \}) = \frac{support(\{ butter, bread \})}{support(\{ bread \})} = \frac23 \]
}}}

And their lift:

{{{
\[ lift(\{ butter \} \Rightarrow \{ bread \}) = \frac{confidence(\{ butter \} \Rightarrow \{ bread \})}{support(\{ bread \})} = 4/3 \]
\[ lift(\{ bread \} \Rightarrow \{ butter \}) = \frac{confidence(\{ bread \} \Rightarrow \{ butter \})}{support(\{ butter \})} = 4/3 \]
}}}

We present rules together with their count, support, confidence, and lift. Count and support of each rule is the same as count and support of the frequent itemset from which this rule was extracted.

|! Association rule |! Count |! Support |! Confidence |! Lift
| {{{$ \{ eggs \} \Rightarrow \{ bacon \} $}}} | 2 | 1/3 | 2/3 | 2
| {{{$ \{ bacon \} \Rightarrow \{ eggs \} $}}} | 2 | 1/3 | 1 | 2
| {{{$ \{ butter \} \Rightarrow \{ bread \} $}}} | 2 | 1/3 | 2/3 | 4/3
| {{{$ \{ bread \} \Rightarrow \{ butter \} $}}} | 2 | 1/3 | 2/3 | 4/3

With the minimum confidence threshold {{{$minconf = 2/3$}}}, all four rules will be selected. And if we set the confidence threshold {{{$minconf = 1$}}}, only the rule {{{$ \{ bacon \} \Rightarrow \{ eggs \} $}}} will pass it.

Here is a way to interpret this: According to our database of transactions, 100\% of customers who bought bacon have also bought eggs. This statement is supported by 33.33\% of transactions.

!!! Implementation
@sec:APriori-Implementation

We implement both itemset and association rules as classes. 

{{{
\begin{sidewaysfigure}
\centering
\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Chapters/DataMining/figures/APrioriUML.pdf}
\caption{Implementation of the A-Priori algorithm}
\label{figAPrioriUML}
\end{sidewaysfigure}
}}}

!!!! Itemset class

By definition, itemset is just a set of items. However, the A-Priori algorithm assumes that elements of each itemset are sorted and on multiple occations accesses last (greatest)items from the itemset. This means that the ==Itemset== class can not be implemented on to of a ==Set==. It must be an ordered collection and we find ==Array== to be the best and most efficient class to represent itemsets (we will make sure that there are no duplicates when an itemset is created). We also want each itemset to remember its support and confidence. This way, when the A-Priori algorithm finds the collection of frequent itemsets, each itemset will be able to tell you how many times it appeared in the database of transactions and what is its support:

[[[
Array subclass: #Itemset
	instanceVariableNames: 'count support'
	classVariableNames: ''
	package: 'APriori'
]]]

!!!!! Instance Creation

When the itemset is created, we need to mak sure that it has no duplicates and that the elements are sorted (it is an array that represents an ordered set):

[[[
Itemset class >> withAll: aCollection
	| collectionWithoutDuplicates itemset |
	collectionWithoutDuplicates := aCollection asSet asArray.
	itemset := super withAll: collectionWithoutDuplicates.
	itemset sort.
	^ itemset.
]]]

We extend the ==Collection== class with method ==asItemset== that allows us to quickly create itemsets by converting any kind of collection to ==Itemset== class:

[[[
Collection >> asItemset
	^ Itemset withAll: self
]]]

!!!!! Printing

We want to print an itemset as a set using the notation that is used in most literature: elements separated by commas and enclosed in curly braces: {{{$\{1, 2, 3\}$}}}

[[[
Itemset >> printOn: aStream
	aStream
		nextPut: ${;
		nextPutAll: (', ' join: self);
		nextPut: $}.
]]]

!!!!! Equality

The standard equality operation that ==Itemset== inherits from ==SequenceableCollection== (superclass of ==Array==) checks only if the elements of two given itemsets are equal. But we also want to check if count and support of those itemsets is the same. So we override the equality operation in the following way:

[[[
Itemset >> = anObject
	(super = anObject)
		ifFalse: [ ^ false ].
		
	(self count = anObject count)
		ifFalse: [ ^ false ].
	
	(self support = anObject support)
		ifFalse: [ ^ false ].
		
	^ true
]]]

!!!!! Converting to Array

Sometimes we will only need to compare elements of two itemsets, regardless of their count and support. We can do that by converting itemsets to arrays and then comparing them:

[[[
Itemset >> asArray 
	^ Array withAll: self
]]]

!!!!! Subsets and Supersets

An itemset should be able to tell us if it is a superset of another itemset. This will be useful when we count the occurences of a given itemset in a database of transactions (remember that transactions are itemsets). We will iterate through each transaction and check if it is a superset of a given itemset. So we implement a method that checks if all elements of a given itemset are included into the receiver itemset:

[[[
Itemset >> isSupersetOf: anotherItemset
	^ self includesAll: anotherItemset
]]]

When generating association rules from itemsets, we will need to extract all subsets of a given itemset {{{$I$}}}, without an empty set {{{$\varnothing$}}} and the itemset {{{$I$}}} itself. For example, itemset {{{$\{ 1, 2, 3 \}$}}} has 6 such subsets: {{{$\{1\}$}}}, {{{$\{2\}$}}}, {{{$\{3\}$}}}, {{{$\{1, 2\}$}}}, {{{$\{1, 3\}$}}}, and {{{$\{2, 3\}$}}}. We can find them by generating all possible combinations of elements fom itemset {{{$I$}}} and removing the combination that contains all items ({{{$I$}}} itself):

[[[
Itemset >> allSubsets
	^ (self combinations copyWithout: (self asArray)) collect: #asItemset
]]]

Finally, on the prune step of A-Priori algorithm, we have to check if all {{{$(k-1)$}}}-subsets of a given candidate {{{$k$}}}-itemset are frequent. To do that, we first need to generate all subsets of a given itemset {{{$I$}}} whose size is one element less than the size of an {{{$I$}}}. We call them largest subsets. For example, largest subsets of itemset {{{$\{ 1, 2, 3 \}$}}} are {{{$\{1, 2\}$}}}, {{{$\{1, 3\}$}}}, and {{{$\{2, 3\}$}}}. We can find them by iteratively removing one element from {{{$I$}}}:

[[[
Itemset >> allLargestSubsets
	^ self collect: [ :item |
		self copyWithout: item ].
]]]

!!!!! Joining Itemsets

As we have discussed in Section *@sec:APriori-Definition*, the join step of A-Priori algorithm joins every two itemsets that satisfy the following condition: {{{$k$}}}-itemset {{{$I$}}} can be joined with {{{$k$}}}-itemset {{{$J$}}} if they share the first {{{$k-1$}}} elements and the last element of {{{$J$}}} is less than the last element of {{{$I$}}}. To perform this check faster, we don't check if itemsets have same size, because we know that this method will be called by the method ==APriori >> joinFrequentItemsetsOfSize: k== which only iterates over itemsets of size {{{$k$}}}. Notice also that we convert both itemsets to arrays because we only want to compare their elements and not their counts and supports:

[[[
Itemset >> canBeJoinedWith: anotherItemset
	| itemset1WithoutLast itemset2WithoutLast |
	
	itemset1WithoutLast := self asArray copyFrom: 1 to: self size - 1.
	itemset2WithoutLast := anotherItemset asArray copyFrom: 1 to: anotherItemset size - 1.
	
	^ (itemset1WithoutLast = itemset2WithoutLast) and: (self last < anotherItemset last).
]]]

If {{{$k$}}}-itemsets {{{$I$}}} and {{{$J$}}} can be joined, we join them into a new {{{$(k+1)$}}}-itemset which contains the first {{{$k-1$}}} elements which are the same in {{{$I$}}} and {{{$J$}}}, followed by the last element of {{{$I$}}} and then the last element of {{{$J$}}}:

[[[
Itemset >> joinWith: anotherItemset
	| itemsetWithoutLast |
	
	itemsetWithoutLast := self copyFrom: 1 to: self size - 1.
	
	^ (OrderedCollection
		withAll: itemsetWithoutLast)
		add: self last;
		add: anotherItemset last;
		asItemset.
]]]

!!!! AssociationRule class

We implement ==AssociationRule== as a subclass of an ==Association==. Similar to an itemset, an association rule knows its count, support, confidence, and lift.

[[[
Association subclass: #AssociationRule
	instanceVariableNames: 'count support confidence lift'
	classVariableNames: ''
	package: 'APriori'
]]]

!!!!! Instance Creation

To create association rules, we extend ==Association== class with a method ==asAssociationRule== that converts a given association to an association rule:

[[[
Association >> asAssociationRule
	^ AssociationRule key: self key value: self value
]]]

We also add an operator ===>== to the ==Itemset== class that allows us to create association rules simply by combining two itemsets. For example, we can create an itemset {{{$\{a, b, c\} \Rightarrow \{d, e\}$}}} with a simple expression ==#(a b c) asItemset => #(d e) asItemset==.

[[[
Itemset >> => anotherItemset
	^ (self -> anotherItemset) asAssociationRule
]]]

We also add a method to the ==Itemset== class that will allow us to generate all possible association rules from the given itemset. For example, itemset {{{$\{1, 2, 3\}$}}} produces six association rules:

{{{
\[ \{ 1 \} \Rightarrow \{ 2, 3 \}  \]
\[ \{ 2 \} \Rightarrow \{ 1, 3 \}  \]
\[ \{ 3 \} \Rightarrow \{ 1, 2 \}  \]
\[ \{ 1, 2 \} \Rightarrow \{ 3 \}  \]
\[ \{ 1, 3 \} \Rightarrow \{ 2 \}  \]
\[ \{ 2, 3 \} \Rightarrow \{ 1 \}  \]
}}}

[[[
Itemset >> allAssociationRules
	^ self allSubsets collect: [ :eachSubset |
		eachSubset => (self difference: eachSubset) ].
]]]

!!!!! Printing

The following method will print association rules in the form =={1, 2} => {3, 4}==:

[[[
printOn: aStream
	self key printOn: aStream.
	aStream nextPutAll: ' => '.
	self value printOn: aStream.
]]]

!!!!! Equality

For the same reason that made us override the equality operator of Itemset, we override it for the ==AsociationRule==: the implementation of equality check that it inherits from ==Association== only checks the equality of its key and value itemsets, but we also want to check the equality of count, support, confidence, and lift of the given two itemsets. Notice that the first line will check the equality of objects of ==Association==, it will check the equality of keys and values (both itemsets), thus calling the equality method from ==Itemset== class. And this means that count and support of both key and value itemsets will also be compared.

[[[
= anObject
	(super = anObject)
		ifFalse: [ ^ false ].
		
	^ { self count . self support . self confidence . self lift } = { anObject count . anObject support . anObject confidence . anObject lift }
]]]

!!!!! Converting to Itemset

Association rule can be turned into an itemset by uniting its key and value itemsets. For example, the rule {{{$\{a, b, c\} \Rightarrow \{ d, e \}$}}} can be converted to an itemset {{{$\{ a, b, c, d, e \}$}}}:

[[[
asItemset	
	^ self key union: self value
]]]

!!! Practical Examples
@sec:APriori-PracticalExamples

!!! Appendix: Proving the A-Priori Property

You are given two itemsets

{{{
\begin{align*}
I &= \{ \text{bread}, \text{butter} \} \\
J &= \{ \text{bread}, \text{butter}, \text{salt} \}
\end{align*}
}}}

{{{$J$}}} is a superset of {{{$I$}}} because it contains all items of {{{$I$}}} (bread and butter) and some other items (salt).

Suppose that in a database of transactions {{{$T$}}} itemset {{{$I$}}} appears 3 times, meaning that there were 3 customers who bought bread and butter.

{{{
\[ count(I) = 3 \]
}}}

Without knowing anything else about the transaction dataset, we can be certain that itemset {{{$J$}}} could not appear in it more than 3 times. Why? Imagine that it's not the case, and the count of {{{$J$}}} is greater, let's say that it's equal to 5

{{{
\[ count(J) = 5 \]
}}}

This would mean that there were 5 customers, who bought bread, butter, and salt. But then, each one of them bought bread and butter, which means that {{{$count(I)$}}} is at least 5 (it can be greater because there may be customers who bought bread and butter but no salt).

!!! Appendix: Proving the Correctness of Candidate Generation

It may not be obvious that by joining the set {{{$L_{k-1}$}}} of frequent {{{$(k-1)$}}}-itemsets with itself, using the join operation {{{$L_{k-1} \bowtie L_{k-1}$}}} defined above, we cover all possible itemsets of size {{{$k$}}}. In other words, we need to show that {{{$L_k \subseteq C_k$}}}.

Let's show that an arbitrary frequent {{{$k$}}}-itemset {{{$I_k \in L_k$}}} will be included into {{{$C_k$}}} when we generate {{{$C_k$}}} from {{{$L_{k-1}$}}}:

{{{
\[ I_k = \{ i_1, i_2, \dots, i_k \} \]
}}}

We can extract the following two subsets of size {{{$k-1$}}} from itemset {{{$I_k$}}}:

{{{
\begin{align*}
I_{k-1}^{(1)} &= \{ i_1, i_2, \dots, i_{k-2}, i_{k-1} \} \\
I_{k-1}^{(2)} &= \{ i_1, i_2, \dots, i_{k-2}, i_k \}
\end{align*}
}}}

Based on the A-Priori property, which tells us that every subset of a frequent itemset is also frequent, both {{{$I_{k-1}^{(1)}$}}} and {{{$I_{k-1}^{(2)}$}}} belong to {{{$L_{k-1}$}}} - the set of frequent itemsets of size {{{$k-1$}}}.

{{{
\[ I_{k-1}^{(1)}, I_{k-1}^{(2)} \in L_{k-1} \]
}}}

You might have noticed that we selected {{{$I_{k-1}^{(1)}$}}} and {{{$I_{k-1}^{(2)}$}}} in such way that they satisfy the A-Priori's join condition described in Function *@funJoinCondition*:	

# They share the first {{{$k-2$}}} items
# The last element of {{{$I_{k-1}^{(1)}$}}} is smaller than the last element of {{{$I_{k-1}^{(2)}$}}} because elements of itemset {{{$I_k$}}} are sorted and therefore {{{$i_{k-1} < i_k$}}}

This means that during the join step on set {{{$L_{k-1}$}}}, itemsets {{{$I_{k-1}^{(1)}$}}} and {{{$I_{k-1}^{(2)}$}}} will be joined and therefore:

{{{
\[ I_k \in L_{k-1} \bowtie L_{k-1} \]
}}}

{{{$I_k$}}} will not be removed during the prune step because, as we said before, based on the A-Priori property, all subsets of {{{$I_k$}}} are frequent.

Therefore,

{{{
\[ \forall I_k \in L_k \quad I_k \in C_k \]
}}}

Which means that

{{{
\[ L_k \subseteq C_k \]
}}}

!!! Recommended Reading
@sec:APriori-RecommendedReading

# ""Fast Algorithm for Mining Association Rules"" by Rakesh Agrawal and Ramakrishnan Srikant ${cite:Agra94a}$
# ""Frequent item set mining"" by Christian Borgelt ${cite:Borg12a}$
# Chapter 6 of ""Data Mining: Concepts and Techniques"" by Jiawei Han, Micheline Kamber, and Jian Pei ${cite:Han11a}$
# Chapter 6 of ""Mining of Massive Datasets"" by Jure Leskovec, Anand Rajaraman, and Jeffrey D. Ullman ${cite:Lesk14a}$

!!! List of notations used in this chapter
@sec:APriori-Notation

|! Symbol |! Interpretation
| {{{$i_1, \dots, i_k$}}} | items (products)
| {{{$t_1, \dots, t_m$}}} | transactions
| {{{$I, J, Q$}}} | itemsets
| {{{$I_k, J_k, Q_k$}}} | itemsets of size k or k-itemsets
| {{{$I \Rightarrow J$}}} | association rule
| {{{$B$}}} | item base
| {{{$T$}}} | database of transactions
| {{{$count(I)$}}} | count of itemset {{{$I$}}} in a database of transactions {{{$T$}}}
| {{{$support(I)$}}} | support of itemset {{{$I$}}} in a database of transactions {{{$T$}}}
| {{{$confidence(I \Rightarrow J)$}}} | confidence of association rule {{{$I \Rightarrow J$}}} in a database of transactions {{{$T$}}}
| {{{$lift(I \Rightarrow J)$}}} | lift of association rule {{{$I \Rightarrow J$}}} in a database of transactions {{{$T$}}}
| {{{$minsup$}}} | minimum support threshold
| {{{$minconf$}}} | minimum confidence threshold
| {{{$minlift$}}} | minimum lift threshold
| {{{$C_k$}}} | set of candidate itemsets of size k
| {{{$L_k$}}} | set of frequent itemsets of size k
| {{{$L_k \bowtie L_k$}}} | set {{{$L_k$}}} joined with itself according to the rules defined in this chapter
| {{{$Freq$}}} | a set of all frequent itemsets
| {{{$\mathbb{P}(B)$}}} | powerset of {{{B}}}
| {{{$P(J \vert I)$}}} | conditional probability of {{{$J$}}} given {{{$I$}}}
