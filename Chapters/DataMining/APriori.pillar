!! A-Priori Algorithm for Mining Frequent Itemsets

In order to improve its sales, a small supermarket has collected the receipts from each customer during one month. They want you to analyse those receipts and find products that are often purchased together and propose a set of rules to recommend products to a customer.

For example, you can produce a rule =={wine, ham} => {cheese, bread}==  which means that customers who buy wine and ham, are also likely to buy cheese and bread. So we can recommend these products to them.


!!! What is it?
@sec:APriori-WhatIsIt

A-Priori was originally designed by Agrawal et al. ${cite:Agra94a}$ to discover association rules between items in a large database if sales transactions.

!!! Applications
@sec:APriori-Applications

The applications of A-Priori go far beyond market basket analysis.


!!! Formal Definition
@sec:APriori-Definition

!!!! The Problem of Mining Frequent Itemsets

We are given a set of items called ''item base''

{{{
\[ B = \{ i_1, \dots, i_n \} \]
}}}

And a set of ''transactions'' where each transaction is a set of items from the item base {{{$B$}}}

{{{
\[ T = \{ t_1, \dots, t_m \} \]
\[ t_k \subseteq B \quad \forall t_k \in T \]
}}}

You can think of items as products that are sold at the supermarket, and each transaction as a list of products purchased by one customer (list of products on the receipt).

We use the word ''itemset'' to denote any set of items selected from the item base:

{{{
\[ I \subseteq B \]
}}}

In fact, every transaction is an itemset (a set of items that were purchased by acustomer) and the item base itself is also an itemset (a set of all products in the store).

The ''cover'' of an itemset {{{$I$}}} in a set of transactions {{{$T$}}} is a subset of transactions that contain all items from this itemset

{{{
\[ K_T(I) = \{ t_k \in T | I \subseteq t_k \} \]
}}}

The ''count'' of an item set {{{$I$}}} in a set of trasactions {{{$T$}}} is the number of transactions in which this itemset appears

{{{
\[ \eta_T(I) = | K_T(I) | \]
}}}

The ''support'' of an itemset {{{$I$}}} is the relative frequency of this itemset in a set of transactions {{{$T$}}}

{{{
\[ s_T(I) = \frac{\eta_T(I)}{|T|} \]
}}}

where {{{$|T|$}}} is the total number of transactions. Support of an itemset is the percentage of transactions that contain this all of its items.

Given some ''minimum support'' {{{$ s_{min} \in \mathbb{N} $}}}, an itemset {{{$I$}}} is called ''frequent'' if its support {{{$s_T(I)$}}} is greater than or equal to the minimum support. We can define a set of all itemsets that are frequent in a set of transactions {{{$T$}}}:

{{{
\[ F_T(s_{min}) = \{ I \subseteq B | s_T(I) \geq s_{min} \} \]
}}}

The goal of frequent itemset mining is to find the set of all frequent itemsets {{{$F_T(s_{min})$}}} given a set of transactions {{{$T$}}} and a minimum support {{{$s_{min}$}}}.

!!!! Extension of the problem: Association Rules Mining

Once we have found the set of frequent itemsets, we can represent each itemset as a rule in form


!!!! Why this is a complicated problem?

At first sight, it may seem that you can solve this problem simply by iterating over all possible itemsets and selecting the ones that pass the minimum support threshold.

However, the number of possible itemsets grows very quickly as you increase the size of an item base {{{$B$}}}. Turns out that even for the smallest stores that sell very limited amount of products, a set of all possible combinations of those products will be so big that any analysis on this set becomes infeasible.

Let's take a closer look at this number. If {{{$B$}}} is the item base (for example, a list of all products sold by a supermarket), then the collection of all possible subsets of {{{$B$}}} is called ''powerset'' and denoted {{{$\mathbb{P}(B)$}}}.

{{{
\[ |\mathbb{P}(B)| = 2^{|B|} \]
}}}

+Hasse diagrams showing sets of all possible itemsets as powersets over the itembase B = {a}, B = {a, b}, and B = {a, b, c}. You can see how fast these diagrams are growing.>figures/Powersets.png+

!!!! The A-Priori Property

The idea behind A-Priori algorithm is based on a simple intuitive property of itemsets: ''if itemset I appears in transactions k times, then there can be no itemset J that contains all elements from I and appers more than k times''.

In other words,

{{{
\[ \forall I \subseteq J \subseteq B\ \colon\quad \eta_T(I) \geq \eta_T(J) \]
}}}

This fact will be central to everything what comes next, so we will give a small example to convince you in its validity.

You are given two itemsets

{{{
\begin{align*}
I &= \{ \text{bread}, \text{butter} \} \\
J &= \{ \text{bread}, \text{butter}, \text{salt} \}
\end{align*}
}}}

{{{$J$}}} is a superset of {{{$I$}}} because it contains all items of {{{$I$}}} (bread and butter) and some other items (salt).

Suppose that in a database of transactions {{{$T$}}} itemset {{{$I$}}} appears 3 times, meaning that there were 3 customers who bought bread and butter.

{{{
\[ \eta_T(I) = 3 \]
}}}

Without knowing anything else about the transaction dataset, we can be certain that itemset {{{$J$}}} could not appear in it more than 3 times. Why? Imagine that it's not the case, and the count of {{{$J$}}} is greater, let's say that it's equal to 5

{{{
\[ \eta_T(J) = 5 \]
}}}

This would mean that there were 5 customers, who bought bread, butter, and salt. But then, each one of them bought bread and butter, which means that {{{$\eta_T(I)$}}} is at least 5 (it can be greater because there may be customers who bought bread and butter but no salt).

Therefore, if an itemset is not frequent, then no superset of this itemset can be frequent:

{{{
\[ \forall I \subseteq J \subseteq B\ \colon\quad s_T(I) < s_{min}\ \ \Rightarrow\ \ s_T(J) < s_{min} \]
}}}

+Frequent Itemsets>figures/FrequentItemsets.png+

!!!! A-Priori Algorithm

We start the A-Priori algorithm by what is often called an ''"initialization step"'' - we build a set {{{$L_1$}}} of all frequent itemsets of size 1. We think of every item {{{$i$}}} from the item base {{{$B$}}} as an itemset with 1 element {{{$I = \{ i \}$}}}. Then we select only those itemsets whose support {{{$s_t(I$}}} is greater than or equal to the given minimum support {{{$s_{min}$}}}.

Then we repeat the following two steps with {{{$k = 2, 3, \dots$}}} as long as the set {{{$L_{k-1}$}}} of frequent {{{$(k-1)$}}}-itemsets is not empty:

# ''Candidate generation'': we use the set {{{$L_{k-1}$}}} of frequent {{{$(k-1)$}}}-itemsets to generate {{{$C_k$}}} - a set candidate {{{$k$}}}-itemsets.
# ''Frequent itemset selection'': we construct the set {{{$L_k$}}} of frequent {{{$k$}}}-itemsets by selecting only those candidates from {{{$C_k$}}} that pass the minimem support threshold.

To get a better intuition on the flow of the A-Priori algorithm, take a look on Figure *@figAPriori*. We start with a set of frequent items {{{$L_1$}}}, use it to generate candidates {{{$C_2$}}}, then select frequent pairs {{{$L_2$}}}, and continue this process until we get an empty set {{{$L_k = \varnothing$}}}.

+The flow of A-Priori algorithm>figures/APriori.png|label=figAPriori+

The whole algorithm is formally described with pseudocode as Function *@funAPriori*. The function ==generate_candidates== will be defined in the next section, where we will talk about the process of candidate generation.

{{{
\begin{algorithm}[H]
 \KwData{Database of transactions $T$ and a support threshold $s_{min}$}
 \KwResult{A set $F_T(s_{min})$ of all frequent itemsets in $T$}
 ~\\
 \Fn{apriori(T, $s_{min}$)}{
 	$L_1 \gets$ \{frequent 1-itemsets\}\\
 	\For{($k = 2;\ L_{k-1} \neq \varnothing;\ k++$)}{
 		$C_k \gets$ generate\_candidates($L_{k-1}$)\\
		$L_k \gets \{ I \in C_k | s_T(I) \geq s_{min} \}$
 	}
 	$F_T(s_{min}) \gets \bigcup_k L_k$ \\
	\KwRet $F_T(s_{min})$
 }
 \caption{A-Priori algorithm}
 \label{funAPriori}
\end{algorithm}
}}}


!!!!! Candidate Generation for the A-Priori Algorithm

{{{
\begin{algorithm}[H]
 \KwData{A set of frequent ($k-1$)-itemsets $L_{k-1}$}
 \KwResult{A set of candidate $k$-itemsets $C_k$}
 ~\\
 \Fn{generate\_candidates($L_{k-1}$)}{
 	$C_k \gets$ \{\}\\
 	\ForAll(\tcp*[f]{join step}){$I \in L_{k-1}$}{
 		\ForAll{$J \in L_{k-1}$}{
			\If{can\_be\_joined($I$, $J$)}{
 				$C_k$.add(join($I$, $J$))
			}
		}
 	}
 	\ForAll(\tcp*[f]{prune step}){$I \in C_k$}{
 		\ForAll{($k-1$)-subsets $I_{k-1} \subset I$} {
			\If{$I_{k-1} \notin L_{k-1}$}{
				$C_k$.remove($I$)\\
				break
			}
		}
 	}
	\KwRet $C_k$
 }
 \caption{Candidate generation for the A-Priori algorithm}
 \label{funCandidateGeneration}
\end{algorithm}
}}}

{{{
\begin{algorithm}[H]
 \KwData{Two frequent $(k-1)$-itemsets $I, J \in L_{k-1}$ where $I = \{ i_1, i_2, \dots, i_{k-1} \}$ and $J = \{ j_1, j_2, \dots, j_{k-1} \}$}
 \KwResult{A boolean value telling us if $I$ and $J$ can be joined}
 ~\\
 \Fn{can\_be\_joined(I, J)}{
 	\For{$p \gets 1$ \KwTo $k-2$}{
 		\If{$i_p$ != $j_p$}{
			\KwRet false
		}
	 }
	 \KwRet $i_{k-1} < j_{k-1}$
 }
 \caption{Testing if two itemsets can be joined}
 \label{funJoinCondition}
\end{algorithm}
}}}

{{{
\begin{algorithm}[H]
 \KwData{Two frequent $(k-1)$-itemsets $I, J \in L_{k-1}$ where $I = \{ i_1, i_2, \dots, i_{k-1} \}$ and $J = \{ j_1, j_2, \dots, j_{k-1} \}$}
 \KwResult{A new itemset $Q$ of size $k$ constructed by joining $I$ and $J$}
 ~\\
 \Fn{join(I, J)}{
 	$Q \gets \{\}$ \\
 	\For{$p \gets 1$ \KwTo $k-1$}{
 		Q.add($j_p$)
 	}
 	Q.add($j_{k-1}$) \\
 	\KwRet Q
 }
 \caption{Joining two itemsets to generate candidates for the A-Priori algorithm}
 \label{funJoin}
\end{algorithm}
}}}

!!!! Proving the correctness of candidate generation

It may not be obvious that by joining the set {{{$L_{k-1}$}}} of frequent {{{$(k-1)$}}}-itemsets with itself, using the join operation {{{$L_{k-1} \bowtie L_{k-1}$}}} defined above, we cover all possible itemsets of size {{{$k$}}}. In other words, we need to show that {{{$L_k \subseteq C_k$}}}.

Let's show that an arbitrary frequent {{{$k$}}}-itemset {{{$I_k \in L_k$}}} will be included into {{{$C_k$}}} when we generate {{{$C_k$}}} from {{{$L_{k-1}$}}}:

{{{
\[ I_k = \{ i_1, i_2, \dots, i_k \} \]
}}}

We can extract the following two subsets of size {{{$k-1$}}} from itemset {{{$I_k$}}}:

{{{
\begin{align*}
I_{k-1}^{(1)} &= \{ i_1, i_2, \dots, i_{k-2}, i_{k-1} \} \\
I_{k-1}^{(2)} &= \{ i_1, i_2, \dots, i_{k-2}, i_k \}
\end{align*}
}}}

Based on the A-Priori property, which tells us that every subset of a frequent itemset is also frequent, both {{{$I_{k-1}^{(1)}$}}} and {{{$I_{k-1}^{(2)}$}}} belong to {{{$L_{k-1}$}}} - the set of frequent itemsets of size {{{$k-1$}}}.

{{{
\[ I_{k-1}^{(1)}, I_{k-1}^{(2)} \in L_{k-1} \]
}}}

You might have noticed that we selected {{{$I_{k-1}^{(1)}$}}} and {{{$I_{k-1}^{(2)}$}}} in such way that they satisfy the A-Priori's join condition described in Function *@funJoinCondition*:	

# They share the first {{{$k-2$}}} items
# The last element of {{{$I_{k-1}^{(1)}$}}} is smaller than the last element of {{{$I_{k-1}^{(2)}$}}} because elements of itemset {{{$I_k$}}} are sorted and therefore {{{$i_{k-1} < i_k$}}}

This means that during the join step on set {{{$L_{k-1}$}}}, itemsets {{{$I_{k-1}^{(1)}$}}} and {{{$I_{k-1}^{(2)}$}}} will be joined and therefore:

{{{
\[ I_k \in L_{k-1} \bowtie L_{k-1} \]
}}}

{{{$I_k$}}} will not be removed during the prune step because, as we said before, based on the A-Priori property, all subsets of {{{$I_k$}}} are frequent.

Therefore,

{{{
\[ \forall I_k \in L_k \quad I_k \in C_k \]
}}}

Which means that

{{{
\[ L_k \subseteq C_k \]
}}}

!!! Simple Example
@sec:APriori-SimpleExample

|! TID |! Transaction
| 1 | {eggs, milk, butter}
| 2 | {milk, cereal}
| 3 | {eggs, bacon}
| 4 | {bread, butter}
| 5 | {bread, bacon, eggs}
| 6 | {bread, avocado, butter, bananas}


!!! Designing the API
@sec:APriori-API

[[[
groceries := #( 
  (eggs milk butter)
  (milk cereal)
  (eggs bacon)
  (bread butter)
  (bread bacon eggs)
  (bread avocado butter bananas)).
]]]

[[[
apriori := APriori
  transactions: transactions
  supportThreshold: 1/3
  confidenceThreshold: 1/3.
]]]

[[[
itemsets := apriori frequentItemsets.
rules := apriori associationRules.
]]]

[[[
itemsets first count.
itemsets first support.
]]]

[[[
rules first count.
rules first support.
rules first confidence.
rules first lift.
]]]

!!! Writing tests
@sec:APriori-Tests


!!! Implementation
@sec:APriori-Implementation


!!! Practical Examples
@sec:APriori-PracticalExamples

!!! Recommended Reading
@sec:APriori-RecommendedReading

# ""Fast Algorithm for Mining Association Rules"" by Rakesh Agrawal and Ramakrishnan Srikant ${cite:Agra94a}$
# ""Frequent item set mining"" by Christian Borgelt ${cite:Borg12a}$
# Chapter 6 of ""Data Mining: Concepts and Techniques"" by Jiawei Han, Micheline Kamber, and Jian Pei ${cite:Han11a}$
# Chapter 6 of ""Mining of Massive Datasets"" by Jure Leskovec, Anand Rajaraman, and Jeffrey D. Ullman ${cite:Lesk14a}$